{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_MLP_RNN_LSTM_BiLSTM_StackedBiLSTM_IMDB_Dataset (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Omxae15o-f",
        "outputId": "95371419-79df-497d-943a-b9b33c156190"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NEnpSxVIexdr",
        "outputId": "346bbf0e-9ff8-4ab8-e307-a409fe2920d3"
      },
      "source": [
        "import os \n",
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcyjUWnh0EhX"
      },
      "source": [
        "#### Sequence classification\n",
        "\n",
        "Is a predictive modeling problem where you have some sequence of inputs over space or time and the task is to predict a category for the sequence.\n",
        "\n",
        "What makes this problem difficult is that the sequences can vary in length, be comprised of a very large vocabulary of input symbols and may require the model to learn the long-term context or dependencies between symbols in the input sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j8tjatH0Ehd"
      },
      "source": [
        "##### Problem Description\n",
        "\n",
        "IMDB movie review sentiment classification problem.\n",
        "\n",
        "    The Large Movie Review Dataset (often referred to as the IMDB dataset) contains 25,000 highly-polar movie reviews (good or bad) for training and the same amount again for testing. \n",
        "    The problem is to determine whether a given movie review has a positive (1) or negative sentiment (0).\n",
        "\n",
        "Keras comes with in-built IMDB dataset. The __imdb.load_data()__ function allows you to load the dataset in a format that is ready for use in neural network and deep learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYsbLzC00Ehe"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkfGzMvJ0Ehe"
      },
      "source": [
        "#### Importing the classes and functions required "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEpPm4Wn0Ehf"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import imdb \n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten \n",
        "from tensorflow.keras.layers import LSTM, Dropout, SimpleRNN, Bidirectional\n",
        "\n",
        "from sklearn import metrics"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL1Detri0Ehf"
      },
      "source": [
        "Fix random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN-Zs-0g0Ehf"
      },
      "source": [
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmaFnmq60Ehg"
      },
      "source": [
        "##### Load the IMDB dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSGpKr0l0Ehg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc6f408-6ce7-4004-f839-0e8f306e1509"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce66gjTd0Ehg"
      },
      "source": [
        "This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
        "\n",
        "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
        "\n",
        "Ref: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbwckqlB0Ehh"
      },
      "source": [
        "#### Let's inspect the first one sentence of train and its class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ0SS42eF4Vl",
        "outputId": "7afc3fb3-ad8a-4546-afe0-fba74481078b"
      },
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNMAahbm0Ehh",
        "outputId": "3dc293a4-6bf7-47ca-9b5d-767c79e00098"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTJpEZm0Ehi"
      },
      "source": [
        "##### Converting target from single value to list of 2 values (as it is binary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1BHPnb70Ehi"
      },
      "source": [
        "y_train_actual = y_train\n",
        "y_test_actual = y_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Gr3LguVWMx",
        "outputId": "3d126b40-2bb9-46b5-e0dc-13749756519e"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPASKJwJ0Ehi",
        "outputId": "496817d2-067e-4da0-98f9-acaea4aedd8d"
      },
      "source": [
        "arr = y_train  # take sentiment column in df as array\n",
        "arr[:15]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweSOk_JhnWS",
        "outputId": "6144f0a9-156d-45c9-d325-1ce41916db26"
      },
      "source": [
        "\n",
        "y_train = np.zeros((arr.size, arr.max()+1))  # initialize empty (all zero) label array\n",
        "print(y_train[:10])\n",
        "y_train[np.arange(arr.size), arr] = 1  # add ones in indices where we have a value\n",
        "y_train\n",
        "print(y_train[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192FBjo-0Ehi",
        "outputId": "028f1cee-fb5e-4b4f-8d04-a2aabf6eb17e"
      },
      "source": [
        "arr = y_test  # take sentiment column in df as array\n",
        "y_test = np.zeros((arr.size, arr.max()+1))  # initialize empty (all zero) label array\n",
        "y_test[np.arange(arr.size), arr] = 1  # add ones in indices where we have a value\n",
        "y_test"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ULS3dH0Ehj",
        "outputId": "e633d0cf-2629-4845-d437-4c427f3140a8"
      },
      "source": [
        "print(X_train[0])\n",
        "print(\"\\n\")\n",
        "print(\"label - \",y_train[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "\n",
            "\n",
            "label -  [0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uw5SlV80Ehj",
        "outputId": "c7a4b800-02be-4642-d875-1d62af6e868b"
      },
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45vz_X0A0Ehk",
        "scrolled": true,
        "outputId": "a1901dc4-b919-4b12-83dd-12ad949f6cf9"
      },
      "source": [
        "print(np.min(np.min(X_train)))\n",
        "print(np.max(np.max(X_train)))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "88586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPaatTw40Ehk"
      },
      "source": [
        "#### Import the word_index dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm3yABg80Ehl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7e58c6-90af-4cc5-d750-edaba9a20111"
      },
      "source": [
        "word_index = dict([(key, value + 3) for (key, value) in imdb.get_word_index().items()])\n",
        "# The index has to be adjusted according to load_data function shown above. \n",
        "# Because the 'index_from' is set to 3 in load_data function, we need to add 3 to all the word indices. \n",
        "# Also, the indices upto 3 can be filled with appropriate tokens as shown below"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CDC_S-Y0Ehl"
      },
      "source": [
        "word_index1 = dict([(key, value) for (key, value) in imdb.get_word_index().items()])\n",
        "word_index1.get('this')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEDz65iL0Eho",
        "outputId": "d928ed6a-e892-44b5-a78a-e2400ed23838"
      },
      "source": [
        "subset = dict(list(word_index.items())[0:10])\n",
        "subset"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34704,\n",
              " 'hanging': 2348,\n",
              " 'nunnery': 52010,\n",
              " 'sonja': 16819,\n",
              " 'spiders': 16118,\n",
              " 'trawling': 52011,\n",
              " 'tsukino': 52009,\n",
              " 'vani': 63954,\n",
              " 'woods': 1411,\n",
              " 'woody': 2292}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92_nqzpp0Eho"
      },
      "source": [
        "Insert the <PAD> element to the word_index dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ac05qr0Eho"
      },
      "source": [
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P71UDGZC0Eho"
      },
      "source": [
        "Understand the loaded dictionary contest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IxpbW7E0Ehp",
        "outputId": "d21c4b80-0a51-44bc-d779-4c5669198e06"
      },
      "source": [
        "print(word_index['the']) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsRKh5u0Ehp",
        "outputId": "ad952103-4383-40c1-9257-1ee768f1ca0c"
      },
      "source": [
        "print(min(word_index.values()))\n",
        "print(max(word_index.values()))\n",
        "print(len(word_index))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "88587\n",
            "88588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIfrqAYY0Ehp"
      },
      "source": [
        "Set vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz5isWZE0Ehp",
        "outputId": "2ee85f1d-50ab-4cd0-ecf2-c64a7911d537"
      },
      "source": [
        "vocab_size = len(word_index) \n",
        "vocab_size"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88588"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2isZFFf0Ehq"
      },
      "source": [
        "Prepare index_word dic from word_index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx8tTKHW0Ehq"
      },
      "source": [
        "index_word = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ab33eFYAaq",
        "outputId": "c7852e1c-f723-464a-a2ea-709039b29f5e"
      },
      "source": [
        "first_n_items = list(index_word.items())[:30]\n",
        "first_n_items\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(34704, 'fawn'),\n",
              " (52009, 'tsukino'),\n",
              " (52010, 'nunnery'),\n",
              " (16819, 'sonja'),\n",
              " (63954, 'vani'),\n",
              " (1411, 'woods'),\n",
              " (16118, 'spiders'),\n",
              " (2348, 'hanging'),\n",
              " (2292, 'woody'),\n",
              " (52011, 'trawling'),\n",
              " (52012, \"hold's\"),\n",
              " (11310, 'comically'),\n",
              " (40833, 'localized'),\n",
              " (30571, 'disobeying'),\n",
              " (52013, \"'royale\"),\n",
              " (40834, \"harpo's\"),\n",
              " (52014, 'canet'),\n",
              " (19316, 'aileen'),\n",
              " (52015, 'acurately'),\n",
              " (52016, \"diplomat's\"),\n",
              " (25245, 'rickman'),\n",
              " (6749, 'arranged'),\n",
              " (52017, 'rumbustious'),\n",
              " (52018, 'familiarness'),\n",
              " (52019, \"spider'\"),\n",
              " (68807, 'hahahah'),\n",
              " (52020, \"wood'\"),\n",
              " (40836, 'transvestism'),\n",
              " (34705, \"hangin'\"),\n",
              " (2341, 'bringing')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Kc674M3O0Ehq",
        "outputId": "55b14dd1-ecf2-42d8-ce6b-c8e7df4435b7"
      },
      "source": [
        "# Example to get the value corresponding to a key\n",
        "index_word.get(220)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'almost'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh6pbM-90Ehr"
      },
      "source": [
        "Define seq2text function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8mh_NKe0Ehr"
      },
      "source": [
        "def seq2text(seq):\n",
        "    return ' '.join([index_word.get(i) for i in seq])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQD2WK1T0Ehr",
        "scrolled": true,
        "outputId": "8a3a897d-1726-495e-ddcd-90b6e35f900b"
      },
      "source": [
        "print(X_train[0])\n",
        "print(seq2text(X_train[0]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a_VOX680Ehr",
        "scrolled": true,
        "outputId": "a1de37f2-dfa9-484f-c373-cd5dd5c90de8"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Meg9-C0Ehs"
      },
      "source": [
        "#### Truncate or pad the input sequences so that they are all the same length for modeling. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM0ObeqM0Ehs"
      },
      "source": [
        "# truncate and pad input sequences\n",
        "max_seq_length = 500\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_seq_length, padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_seq_length, padding='post')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzMum_ZT0Ehu"
      },
      "source": [
        "##### Inspect the same sentences after padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX6C9Cqc0Ehu",
        "outputId": "636db347-1a23-41ab-874c-972d36ecd64f"
      },
      "source": [
        "print(X_train[0:1], y_train[0:1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    1    14    22    16    43   530   973  1622  1385    65   458  4468\n",
            "     66  3941     4   173    36   256     5    25   100    43   838   112\n",
            "     50   670 22665     9    35   480   284     5   150     4   172   112\n",
            "    167 21631   336   385    39     4   172  4536  1111    17   546    38\n",
            "     13   447     4   192    50    16     6   147  2025    19    14    22\n",
            "      4  1920  4613   469     4    22    71    87    12    16    43   530\n",
            "     38    76    15    13  1247     4    22    17   515    17    12    16\n",
            "    626    18 19193     5    62   386    12     8   316     8   106     5\n",
            "      4  2223  5244    16   480    66  3785    33     4   130    12    16\n",
            "     38   619     5    25   124    51    36   135    48    25  1415    33\n",
            "      6    22    12   215    28    77    52     5    14   407    16    82\n",
            "  10311     8     4   107   117  5952    15   256     4 31050     7  3766\n",
            "      5   723    36    71    43   530   476    26   400   317    46     7\n",
            "      4 12118  1029    13   104    88     4   381    15   297    98    32\n",
            "   2071    56    26   141     6   194  7486    18     4   226    22    21\n",
            "    134   476    26   480     5   144    30  5535    18    51    36    28\n",
            "    224    92    25   104     4   226    65    16    38  1334    88    12\n",
            "     16   283     5    16  4472   113   103    32    15    16  5345    19\n",
            "    178    32     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]] [[0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Re4RKoW0Ehv"
      },
      "source": [
        "#### Load the GloVe word embedding file into memory as a dictionary of word to embedding array.\n",
        "\n",
        "__Note__: Filter the embedding for the unique words in the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM9LO2vS0-pg"
      },
      "source": [
        "#!gdown --id 1wg8LXo5UuFWMMP-x5xatcgdwVTKUr6nM # Download the glove embedding file"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO77PD23eUzX",
        "outputId": "42956133-650d-431d-a122-df9d2257ca40"
      },
      "source": [
        "import os\n",
        "files = os.listdir(os.curdir)  #files and directories\n",
        "files"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'gdrive', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxwB9fLw0Ehv",
        "outputId": "f5cf5da2-d12e-43ef-cbc3-af11437f3e1e"
      },
      "source": [
        "word_embeddings = dict()\n",
        "\n",
        "#f = open('../glove.6B.100d.txt', encoding=\"utf8\")  # In your case .. may not required in the path.\n",
        "\n",
        "f = open('/content/gdrive/MyDrive/sentiment /glove.6B.100d.txt', encoding=\"utf8\")  # In your case .. may not required in the path.\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = embedding_vector\n",
        "f.close()\n",
        "\n",
        "print('Loaded %s word vectors.' % len(word_embeddings))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U2_KJoI0Ehw",
        "outputId": "f3e9a2e7-f916-4096-9bb1-3a783b2dcceb"
      },
      "source": [
        "word_embeddings_subset = dict(list(word_embeddings.items())[0:4])\n",
        "word_embeddings_subset"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
              "         0.10663  ,  0.038867 ,  0.35481  ,  0.06351  , -0.094189 ,\n",
              "         0.15786  , -0.81665  ,  0.14172  ,  0.21939  ,  0.58505  ,\n",
              "        -0.52158  ,  0.22783  , -0.16642  , -0.68228  ,  0.3587   ,\n",
              "         0.42568  ,  0.19021  ,  0.91963  ,  0.57555  ,  0.46185  ,\n",
              "         0.42363  , -0.095399 , -0.42749  , -0.16567  , -0.056842 ,\n",
              "        -0.29595  ,  0.26037  , -0.26606  , -0.070404 , -0.27662  ,\n",
              "         0.15821  ,  0.69825  ,  0.43081  ,  0.27952  , -0.45437  ,\n",
              "        -0.33801  , -0.58184  ,  0.22364  , -0.5778   , -0.26862  ,\n",
              "        -0.20425  ,  0.56394  , -0.58524  , -0.14365  , -0.64218  ,\n",
              "         0.0054697, -0.35248  ,  0.16162  ,  1.1796   , -0.47674  ,\n",
              "        -2.7553   , -0.1321   , -0.047729 ,  1.0655   ,  1.1034   ,\n",
              "        -0.2208   ,  0.18669  ,  0.13177  ,  0.15117  ,  0.7131   ,\n",
              "        -0.35215  ,  0.91348  ,  0.61783  ,  0.70992  ,  0.23955  ,\n",
              "        -0.14571  , -0.37859  , -0.045959 , -0.47368  ,  0.2385   ,\n",
              "         0.20536  , -0.18996  ,  0.32507  , -1.1112   , -0.36341  ,\n",
              "         0.98679  , -0.084776 , -0.54008  ,  0.11726  , -1.0194   ,\n",
              "        -0.24424  ,  0.12771  ,  0.013884 ,  0.080374 , -0.35414  ,\n",
              "         0.34951  , -0.7226   ,  0.37549  ,  0.4441   , -0.99059  ,\n",
              "         0.61214  , -0.35111  , -0.83155  ,  0.45293  ,  0.082577 ],\n",
              "       dtype=float32),\n",
              " '.': array([-0.33979  ,  0.20941  ,  0.46348  , -0.64792  , -0.38377  ,\n",
              "         0.038034 ,  0.17127  ,  0.15978  ,  0.46619  , -0.019169 ,\n",
              "         0.41479  , -0.34349  ,  0.26872  ,  0.04464  ,  0.42131  ,\n",
              "        -0.41032  ,  0.15459  ,  0.022239 , -0.64653  ,  0.25256  ,\n",
              "         0.043136 , -0.19445  ,  0.46516  ,  0.45651  ,  0.68588  ,\n",
              "         0.091295 ,  0.21875  , -0.70351  ,  0.16785  , -0.35079  ,\n",
              "        -0.12634  ,  0.66384  , -0.2582   ,  0.036542 , -0.13605  ,\n",
              "         0.40253  ,  0.14289  ,  0.38132  , -0.12283  , -0.45886  ,\n",
              "        -0.25282  , -0.30432  , -0.11215  , -0.26182  , -0.22482  ,\n",
              "        -0.44554  ,  0.2991   , -0.85612  , -0.14503  , -0.49086  ,\n",
              "         0.0082973, -0.17491  ,  0.27524  ,  1.4401   , -0.21239  ,\n",
              "        -2.8435   , -0.27958  , -0.45722  ,  1.6386   ,  0.78808  ,\n",
              "        -0.55262  ,  0.65     ,  0.086426 ,  0.39012  ,  1.0632   ,\n",
              "        -0.35379  ,  0.48328  ,  0.346    ,  0.84174  ,  0.098707 ,\n",
              "        -0.24213  , -0.27053  ,  0.045287 , -0.40147  ,  0.11395  ,\n",
              "         0.0062226,  0.036673 ,  0.018518 , -1.0213   , -0.20806  ,\n",
              "         0.64072  , -0.068763 , -0.58635  ,  0.33476  , -1.1432   ,\n",
              "        -0.1148   , -0.25091  , -0.45907  , -0.096819 , -0.17946  ,\n",
              "        -0.063351 , -0.67412  , -0.068895 ,  0.53604  , -0.87773  ,\n",
              "         0.31802  , -0.39242  , -0.23394  ,  0.47298  , -0.028803 ],\n",
              "       dtype=float32),\n",
              " 'of': array([-0.1529  , -0.24279 ,  0.89837 ,  0.16996 ,  0.53516 ,  0.48784 ,\n",
              "        -0.58826 , -0.17982 , -1.3581  ,  0.42541 ,  0.15377 ,  0.24215 ,\n",
              "         0.13474 ,  0.41193 ,  0.67043 , -0.56418 ,  0.42985 , -0.012183,\n",
              "        -0.11677 ,  0.31781 ,  0.054177, -0.054273,  0.35516 , -0.30241 ,\n",
              "         0.31434 , -0.33846 ,  0.71715 , -0.26855 , -0.15837 , -0.47467 ,\n",
              "         0.051581, -0.33252 ,  0.15003 , -0.1299  , -0.54617 , -0.37843 ,\n",
              "         0.64261 ,  0.82187 , -0.080006,  0.078479, -0.96976 , -0.57741 ,\n",
              "         0.56491 , -0.39873 , -0.057099,  0.19743 ,  0.065706, -0.48092 ,\n",
              "        -0.20125 , -0.40834 ,  0.39456 , -0.02642 , -0.11838 ,  1.012   ,\n",
              "        -0.53171 , -2.7474  , -0.042981, -0.74849 ,  1.7574  ,  0.59085 ,\n",
              "         0.04885 ,  0.78267 ,  0.38497 ,  0.42097 ,  0.67882 ,  0.10337 ,\n",
              "         0.6328  , -0.026595,  0.58647 , -0.44332 ,  0.33057 , -0.12022 ,\n",
              "        -0.55645 ,  0.073611,  0.20915 ,  0.43395 , -0.012761,  0.089874,\n",
              "        -1.7991  ,  0.084808,  0.77112 ,  0.63105 , -0.90685 ,  0.60326 ,\n",
              "        -1.7515  ,  0.18596 , -0.50687 , -0.70203 ,  0.66578 , -0.81304 ,\n",
              "         0.18712 , -0.018488, -0.26757 ,  0.727   , -0.59363 , -0.34839 ,\n",
              "        -0.56094 , -0.591   ,  1.0039  ,  0.20664 ], dtype=float32),\n",
              " 'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
              "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
              "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
              "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
              "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
              "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
              "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
              "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
              "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
              "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
              "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
              "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
              "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
              "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
              "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
              "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
              "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3tNv0A00Ehw"
      },
      "source": [
        "Next, create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
        "\n",
        "The result is a matrix of weights only for words we will see during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs0Bkbkt0Ehw"
      },
      "source": [
        "embedding_vector_length = 100\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_vector_length))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = word_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdtXRqEt0Ehx"
      },
      "source": [
        "For understanding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwe0epj20Ehx",
        "outputId": "0e153394-8b9f-42af-f92d-50a0dc3c23a5"
      },
      "source": [
        "print(index_word[4])\n",
        "print(word_embeddings.get('the'))\n",
        "print(embedding_matrix[4])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "[-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172    0.043953\n",
            " -0.39140999  0.3344     -0.57545     0.087459    0.28786999 -0.06731\n",
            "  0.30906001 -0.26383999 -0.13231    -0.20757     0.33395001 -0.33848\n",
            " -0.31742999 -0.48335999  0.1464     -0.37303999  0.34577     0.052041\n",
            "  0.44946    -0.46970999  0.02628    -0.54154998 -0.15518001 -0.14106999\n",
            " -0.039722    0.28277001  0.14393     0.23464    -0.31020999  0.086173\n",
            "  0.20397     0.52623999  0.17163999 -0.082378   -0.71787    -0.41531\n",
            "  0.20334999 -0.12763     0.41367     0.55186999  0.57907999 -0.33476999\n",
            " -0.36559001 -0.54856998 -0.062892    0.26583999  0.30204999  0.99774998\n",
            " -0.80480999 -3.0243001   0.01254    -0.36941999  2.21670008  0.72201002\n",
            " -0.24978     0.92136002  0.034514    0.46744999  1.10790002 -0.19358\n",
            " -0.074575    0.23353    -0.052062   -0.22044     0.057162   -0.15806\n",
            " -0.30798    -0.41624999  0.37972     0.15006    -0.53211999 -0.20550001\n",
            " -1.25259995  0.071624    0.70564997  0.49744001 -0.42063001  0.26148\n",
            " -1.53799999 -0.30223    -0.073438   -0.28312001  0.37103999 -0.25217\n",
            "  0.016215   -0.017099   -0.38984001  0.87423998 -0.72569001 -0.51058\n",
            " -0.52028    -0.1459      0.82779998  0.27061999]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4CC_DEO0Ehx"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3OeIGMm0Ehy"
      },
      "source": [
        "We chose the 100-dimensional vector, therefore the Embedding layer must be defined with output_dim set to 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkCeLQ80Ehy"
      },
      "source": [
        "### MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leWGWbnj0Ehy",
        "outputId": "e300f82b-d75b-4818-ea4b-32c7f5631963"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEFHXBA80Ehz",
        "outputId": "f533a4bf-92b8-477a-e005-16c4f4b2935d"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88588, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7I81-C20Ehz"
      },
      "source": [
        "* __Embedding Layer__ requires the following arguments -\n",
        "   - input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "   - output_dim: Integer. Dimension of the dense embedding.\n",
        "   - input_length: Length of input sequences. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
        "   \n",
        "   \n",
        "* This layer can only be used as the first layer in a model.\n",
        "\n",
        "Reference: https://keras.io/api/layers/core_layers/embedding/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dfF2u4q0Ehz"
      },
      "source": [
        "input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "hl1_embedded = Embedding(input_dim=vocab_size, \n",
        "                         output_dim=embedding_vector_length,\n",
        "                         weights=[embedding_matrix],\n",
        "                         trainable=True) (input)\n",
        "h12_flatten = Flatten()(hl1_embedded)\n",
        "h13_dense = Dense(100, activation='relu')(h12_flatten)\n",
        "h14_dropout = Dropout(0.2)(h13_dense)\n",
        "h15_dense = Dense(10, activation='relu')(h14_dropout)\n",
        "h16_dropout = Dropout(0.2)(h15_dense)\n",
        "output = Dense(2, activation='softmax')(h16_dropout)\n",
        "\n",
        "model = Model(input, output)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T5esGbp0Eh1",
        "outputId": "58f15186-4ccc-4004-957a-f43d4c9139ba"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 500, 100)          8858800   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               5000100   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,859,932\n",
            "Trainable params: 13,859,932\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmtmWZTA0Eh3",
        "outputId": "2757dafa-05be-4aa3-ecf1-18facfb07b44"
      },
      "source": [
        "model.get_layer('embedding').output"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 500, 100) dtype=float32 (created by layer 'embedding')>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7fHfoCU0Eh4"
      },
      "source": [
        "Because it is a binary classification problem, log loss is used as the loss function (binary_crossentropy in Keras). \n",
        "\n",
        "The efficient ADAM optimization algorithm is used. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyyBC-kf0Eh4"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsxakJgW0Eh4",
        "outputId": "2990e1f0-385c-4bab-8899-05640b540ba2"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 [==============================] - 33s 160ms/step - loss: 0.6996 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/2\n",
            "196/196 [==============================] - 31s 156ms/step - loss: 0.6934 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f192065d510>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD8CwR56ynp3",
        "outputId": "be9926d3-1440-4495-911d-f19c105ea9bf"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred[0:5])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.50075805 0.49924195]\n",
            " [0.50075805 0.49924195]\n",
            " [0.50075805 0.49924195]\n",
            " [0.50075805 0.49924195]\n",
            " [0.50075805 0.49924195]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJv43TDpynp4"
      },
      "source": [
        "y_pred =[]\n",
        "for i in Y_pred:\n",
        "    y_pred.append(np.argmax(i))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJB9YHI2ynp4",
        "outputId": "6c5604d6-cffa-4ef0-9b09-8c4c60787456"
      },
      "source": [
        "print(y_pred[0:5])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMHTPLAQynp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7558e3-cf95-4892-d4f1-5ebf8b01a3f9"
      },
      "source": [
        "# print the confusion matrix\n",
        "metrics.confusion_matrix(y_test_actual, y_pred)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12500,     0],\n",
              "       [12500,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxAdjCbN8wHw",
        "outputId": "0ca7f71f-5797-48f0-cae9-4467e8b17a5a"
      },
      "source": [
        "metrics.accuracy_score(y_test_actual, y_pred)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KFhUpWE9AX0",
        "outputId": "f6412d16-5e27-4a14-f044-74aaffa9a22f"
      },
      "source": [
        "metrics.precision_score(y_test_actual, y_pred)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R61boUqQ9A38",
        "outputId": "0779499a-70c5-4e45-f301-e3765eb48c56"
      },
      "source": [
        "metrics.recall_score(y_test_actual, y_pred)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dq2xMM60Eh5"
      },
      "source": [
        "__Problems with MLP for sequence data__:\n",
        "    - Inputs, Outputs can be different lengths in different examples\n",
        "    - Does not share features learned across different positions of text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2eWT-hy0Eh5"
      },
      "source": [
        "### Simple RNN \n",
        "    * RNNS are good at processing Sequential data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73_DFg1g0Eh6"
      },
      "source": [
        "1. A single time step of the input is supplied to the network i.e. xt is supplied to the network\n",
        "2. We then calculate its current state using a combination of the current input and the previous state i.e. we calculate ht\n",
        "3. The current ht becomes ht-1 for the next time step\n",
        "4. We can go as many time steps as the problem demands and combine the information from all the previous states\n",
        "5. Once all the time steps are completed the final current state is used to calculate the output yt\n",
        "6. The output is then compared to the actual output and the error is generated\n",
        "7. The error is then backpropagated to the network to update the weights and the network is trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vgmt-yo0Eh6",
        "outputId": "91d21eaf-bc3a-4cd3-f47a-23e4b9d3eb80"
      },
      "source": [
        "input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "hl1_embedded = Embedding(input_dim=vocab_size, \n",
        "                         output_dim=embedding_vector_length,\n",
        "                         weights=[embedding_matrix],\n",
        "                         trainable=True)(input)\n",
        "h12_rnn = SimpleRNN(100)(hl1_embedded)\n",
        "h13_dropout = Dropout(0.2)(h12_rnn)\n",
        "output = Dense(2, activation='softmax')(h13_dropout)\n",
        "\n",
        "model = Model(input, output)\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 500, 100)          8858800   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               20100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,879,102\n",
            "Trainable params: 8,879,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8INBy9Qpise",
        "outputId": "0af5c460-905c-4375-af68-7c41139cb6cc"
      },
      "source": [
        "(100+100)*100+100"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20100"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwTDGqaz0Eh8"
      },
      "source": [
        "* The formula for calculating the weights is as follows:\n",
        "\n",
        "      (num_features + num_units)* num_units + num_units\n",
        "\n",
        "    Explanation:\n",
        "\n",
        "      num_units = equals the number of units in the RNN\n",
        "\n",
        "      num_features = equals the number features of your input\n",
        "\n",
        "`= (100 + 100) * 100 + 100 = 20100`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lz6rXiq0Eh-"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTbpWXVk0Eh_",
        "outputId": "d7401cc3-70ca-460c-f50a-83b776ddab2c"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 [==============================] - 73s 366ms/step - loss: 0.6996 - accuracy: 0.5049 - val_loss: 0.6956 - val_accuracy: 0.5050\n",
            "Epoch 2/2\n",
            "196/196 [==============================] - 72s 370ms/step - loss: 0.6940 - accuracy: 0.5190 - val_loss: 0.6932 - val_accuracy: 0.5027\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f192117d750>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmxWCnSOyXHO",
        "outputId": "f9db54b9-5623-47fd-8314-659487e26354"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred[0:5])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.54685634 0.4531436 ]\n",
            " [0.5532159  0.4467841 ]\n",
            " [0.7923174  0.20768264]\n",
            " [0.5133053  0.48669463]\n",
            " [0.5530843  0.4469157 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpyvNwnjyXHd"
      },
      "source": [
        "y_pred =[]\n",
        "for i in Y_pred:\n",
        "    y_pred.append(np.argmax(i))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hncvgKLqyXHd",
        "outputId": "0539e025-0d32-4266-9ea1-9484a8aaab71"
      },
      "source": [
        "print(y_pred[0:5])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nhv72yhyXHe",
        "outputId": "68b0209c-235c-4cb6-8580-ff89a8335ede"
      },
      "source": [
        "metrics.confusion_matrix(y_test_actual, y_pred)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7249, 5251],\n",
              "       [7182, 5318]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YszxyC_Sy3Ry",
        "outputId": "601ddf14-eb1b-4e9e-9a4a-72033ff80d05"
      },
      "source": [
        "metrics.accuracy_score(y_test_actual, y_pred)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.50268"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ndn3Rdy3R1",
        "outputId": "572b8bb0-eb11-47ab-c395-ef1ad6e85767"
      },
      "source": [
        "metrics.precision_score(y_test_actual, y_pred)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5031696470810862"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWL1-e7qy3R2",
        "outputId": "734e7ee9-211c-424f-dd74-bba0d922ecff"
      },
      "source": [
        "metrics.recall_score(y_test_actual, y_pred)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42544"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nwARTqS0EiA"
      },
      "source": [
        "### LSTM\n",
        "    * LSTM does better than RNN in capturing long-term dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7oKZnLd0EiB"
      },
      "source": [
        "* The first layer is the Embedded layer that uses 100 length vectors to represent each word. \n",
        "\n",
        "* The next layer is the LSTM layer with 100 memory units (smart neurons). \n",
        "\n",
        "* Finally, because this is a classification problem we use a Dense output layer with a single neuron and a sigmoid activation function to make 0 or 1 predictions for the two classes (good and bad) in the problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRFidJ40EiB"
      },
      "source": [
        "input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "hl1_embedded = Embedding(input_dim=vocab_size, \n",
        "                         output_dim=embedding_vector_length,\n",
        "                         weights=[embedding_matrix],\n",
        "                         trainable=True)(input)\n",
        "h12_lstm = LSTM(100)(hl1_embedded)\n",
        "h13_dropout = Dropout(0.2)(h12_lstm)\n",
        "output = Dense(2, activation='softmax')(h13_dropout)\n",
        "\n",
        "model = Model(input, output)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vymy90SV0EiB",
        "outputId": "0f0f3e57-4ffb-4985-d41b-713f85653296"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 500, 100)          8858800   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,939,402\n",
            "Trainable params: 8,939,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxEjplKF0EiC"
      },
      "source": [
        "### Number of parameters of an LSTM layer\n",
        "\n",
        "`num_params = [(num_units + input_dim) * num_units+num_units]  * 4`\n",
        "\n",
        "  * *4: there are 4 neural network layers - {W_forget, W_input, W_output, W_cell}\n",
        "\n",
        "`num_params = [(100 + 100) * 100 + 100] * 4 = 80400`\n",
        "\n",
        "https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network/56614978#56614978"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOuTP-IQ0EiC"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoONwpvc0EiD"
      },
      "source": [
        "The model is fit for only 5 epochs because it quickly overfits the problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIsH4NUP0EiE",
        "outputId": "e9a70845-f74c-4a16-8fd7-5f365ee4d3e8"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 [==============================] - 250s 1s/step - loss: 0.6911 - accuracy: 0.5095 - val_loss: 0.6963 - val_accuracy: 0.5017\n",
            "Epoch 2/2\n",
            "196/196 [==============================] - 245s 1s/step - loss: 0.6864 - accuracy: 0.5152 - val_loss: 0.6877 - val_accuracy: 0.5160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f191efd5950>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSGF0R790EiE"
      },
      "source": [
        "#### Make predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR0nlGFL0EiG",
        "outputId": "476b7b9f-058a-425e-9464-4a91c2bd6952"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred[0:5])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.56621027 0.4337898 ]\n",
            " [0.56621027 0.4337898 ]\n",
            " [0.55595917 0.44404083]\n",
            " [0.56621027 0.4337898 ]\n",
            " [0.56621027 0.43378976]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNF17U-t0EiH"
      },
      "source": [
        "y_pred =[]\n",
        "for i in Y_pred:\n",
        "    y_pred.append(np.argmax(i))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fZBrjA20EiH",
        "outputId": "f31eb5db-a2b1-4cd7-a500-3f82b20c4bc1"
      },
      "source": [
        "print(y_pred[0:5])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX3dVx2d0EiI",
        "outputId": "93fea15a-8e02-4e77-f623-06c0de32dd96"
      },
      "source": [
        "metrics.confusion_matrix(y_test_actual, y_pred)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11988,   512],\n",
              "       [11588,   912]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oDKaqCBy7Br",
        "outputId": "9f84c709-220d-4964-d827-369978d03156"
      },
      "source": [
        "metrics.accuracy_score(y_test_actual, y_pred)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.516"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y28e5BaSy7Bs",
        "outputId": "a7cd35e9-92c3-462c-e29c-86219e684759"
      },
      "source": [
        "metrics.precision_score(y_test_actual, y_pred)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6404494382022472"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3sS4ruTy7Bs",
        "outputId": "b012b372-3af3-4916-cace-e4077b5492b7"
      },
      "source": [
        "metrics.recall_score(y_test_actual, y_pred)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07296"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww0HgsUV0EiI"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "    * Bidirectional recurrent neural networks(RNN) are just putting two independent RNNs together. \n",
        "    * The input sequence is fed in normal time order for one network, and in reverse time order for another. \n",
        "    * The outputs of the two networks are usually concatenated at each time step.\n",
        "    * This structure allows the networks to have both backward and forward information about the sequence at every  time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GmogYg60EiJ",
        "outputId": "64cc7961-6679-4cab-c7fc-c8789b13f71a"
      },
      "source": [
        "inputs = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "# Embed each integer in a 100-dimensional vector\n",
        "hl1_embedded = Embedding(input_dim=vocab_size, \n",
        "                         output_dim=embedding_vector_length,\n",
        "                         weights=[embedding_matrix],\n",
        "                         trainable=True)(inputs)\n",
        "\n",
        "# Add a bidirectional LSTM\n",
        "x = Bidirectional(LSTM(100))(hl1_embedded)# Add a classifier\n",
        "outputs = Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 500, 100)          8858800   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 200)              160800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,020,002\n",
            "Trainable params: 9,020,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI8hb7M_0EiJ"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkaUiDhy0EiK"
      },
      "source": [
        "The model is fit for only 5 epochs because it quickly overfits the problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kitQKwy0EiK",
        "outputId": "5769d511-da35-4ce6-f7c8-aecd712e3f17"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 [==============================] - 496s 3s/step - loss: 0.6490 - accuracy: 0.6304 - val_loss: 0.7550 - val_accuracy: 0.5085\n",
            "Epoch 2/2\n",
            "196/196 [==============================] - 463s 2s/step - loss: 0.6323 - accuracy: 0.6523 - val_loss: 0.8277 - val_accuracy: 0.5185\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f191f5ae790>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY69SZ6Y0EiK"
      },
      "source": [
        "#### Make predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qWsqp5O0EiL",
        "outputId": "0255fbbd-9971-49ce-ab5a-56cff03fdcff"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred[0:5])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.11238832 0.88761175]\n",
            " [0.07254743 0.92745256]\n",
            " [0.06103672 0.9389633 ]\n",
            " [0.07777859 0.9222214 ]\n",
            " [0.08684764 0.91315234]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BfQkpVX0EiL"
      },
      "source": [
        "y_pred =[]\n",
        "for i in Y_pred:\n",
        "    y_pred.append(np.argmax(i))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV_7fACI0EiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92fe30d-b354-4a65-9382-9861ebcf8eb8"
      },
      "source": [
        "print(y_pred[0:5])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAPgDF8Y0EiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785c5d31-3196-4192-de2b-4c2f106e2bf6"
      },
      "source": [
        "metrics.confusion_matrix(y_test_actual, y_pred)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  471, 12029],\n",
              "       [    8, 12492]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iZV8vlnzJhx",
        "outputId": "d5f892f7-3933-48ce-c937-3bae8eb5755a"
      },
      "source": [
        "metrics.accuracy_score(y_test_actual, y_pred)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51852"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_mg-fqzJhy",
        "outputId": "83e3bccd-ecdb-469f-934a-98ee69cebe06"
      },
      "source": [
        "metrics.precision_score(y_test_actual, y_pred)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5094408874026345"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aNOaidwzJhy",
        "outputId": "35564c1f-a93b-44bd-fcf8-f6daee02e5d3"
      },
      "source": [
        "metrics.recall_score(y_test_actual, y_pred)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99936"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNsdklZXg1Vq"
      },
      "source": [
        "### Stacked Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEbRiRyWg1V6",
        "outputId": "5b72d0ce-2075-4a8f-be58-21b18c2472dd"
      },
      "source": [
        "inputs = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "# Embed each integer in a 100-dimensional vector\n",
        "embedded = Embedding(input_dim=vocab_size, \n",
        "                     output_dim=embedding_vector_length,\n",
        "                     weights=[embedding_matrix],\n",
        "                     trainable=True)(inputs)\n",
        "\n",
        "# Add a bidirectional LSTM\n",
        "h1_biLSTM = Bidirectional(LSTM(100, return_sequences=True))(embedded)\n",
        "h2_biLSTM = Bidirectional(LSTM(100))(h1_biLSTM)\n",
        "\n",
        "outputs = Dense(2, activation=\"softmax\")(h2_biLSTM)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 500, 100)          8858800   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 500, 200)         160800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 200)              240800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,260,802\n",
            "Trainable params: 9,260,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxo7vXIYg1V8"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yfwx0u_g1V8"
      },
      "source": [
        "The model is fit for only 5 epochs because it quickly overfits the problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOSL-Vxbg1V9",
        "outputId": "e660a855-3e2a-4203-f7dd-425f5bdb2e78"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=2,\n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 [==============================] - 1147s 6s/step - loss: 0.6327 - accuracy: 0.6476 - val_loss: 0.5030 - val_accuracy: 0.7680\n",
            "Epoch 2/2\n",
            "196/196 [==============================] - 1152s 6s/step - loss: 0.4778 - accuracy: 0.7809 - val_loss: 0.3854 - val_accuracy: 0.8402\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f19170153d0>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi33v7C6g1V9"
      },
      "source": [
        "#### Make predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M1T0imug1V-",
        "outputId": "52f4399a-78f1-4c07-bc1f-2c7a72c8c0d0"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred[0:5])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8891576  0.11084244]\n",
            " [0.00590404 0.9940959 ]\n",
            " [0.02117329 0.97882676]\n",
            " [0.7397027  0.26029733]\n",
            " [0.04593107 0.9540689 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwP32Heg1V-"
      },
      "source": [
        "y_pred =[]\n",
        "for i in Y_pred:\n",
        "    y_pred.append(np.argmax(i))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OERyjJTqg1V-",
        "outputId": "8f6d20fe-b50e-483b-a14c-067283fdd6df"
      },
      "source": [
        "print(y_pred[0:5])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfsVjLymg1V_",
        "outputId": "c99b4b71-87c0-43e4-f95b-adc80b5a0bf7"
      },
      "source": [
        "metrics.confusion_matrix(y_test_actual, y_pred)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10486,  2014],\n",
              "       [ 1981, 10519]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdqGwZD6zMB_",
        "outputId": "72cb8b2a-5ae0-4500-8606-f891b11b3bef"
      },
      "source": [
        "metrics.accuracy_score(y_test_actual, y_pred)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8402"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f6etE5JzMB_",
        "outputId": "b2fa4f1d-3b41-476f-a489-9fa3e63cf332"
      },
      "source": [
        "metrics.precision_score(y_test_actual, y_pred)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8393042368148089"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z2BLuVezMCA",
        "outputId": "f46db56e-2df5-4144-e0ee-e3feb41ab264"
      },
      "source": [
        "metrics.recall_score(y_test_actual, y_pred)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84152"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEgXbae30EiO"
      },
      "source": [
        "__References:__\n",
        "\n",
        "    * https://machinelearningmastery.com\n",
        "    * https://keras.io\n",
        "    * http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "    * https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9\n",
        "    * https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "    * https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/\n",
        "    * https://devopedia.org/bidirectional-rnn\n",
        "    * https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889"
      ]
    }
  ]
}